以下のスクリプトの使用は、[mecab-0.996](http://mecab.googlecode.com/svn/trunk/mecab/doc/index.html) と [unidic-mecab_kana-accent-2.1.2_src.zip](http://download.unidic.org/) がインストールされていることを前提としています。
また、MeCab と Unidic の設定は変更せず、デフォルトの状態にしておいてください。
***
### kana-conv.awk
=======
日本語のテキストファイルをカナ表記に変換するスクリプトです。
ヨミはMeCabの解析結果に基づいており、必ずしも正確なものではありません。

### yoko.awk
=======
テキストファイルから、文字・書字形・語彙素を単位としてN-gramを採取するスクリプトです。
複数のファイルの入力に対応しており、マージ機能も備えています。

### sachiko.awk
=======
基本的な機能は yoko.awk と変わりませんが、MeCab と Unidic の環境を整えるのが難しい場合に使用します。
国立国語研究所が提供している「茶まめ」による形態素解析済みのデータを、処理することができます。

### yumi.awk
=======
複数のテキストファイルの中で、一致する文字列ごとに出現回数をカウントするスクリプトです。
単語は一行に一つだけしか書けません。
yoko.awk 、sachiko.awk と同様のマージ機能を備えています。

### eriko.awk
=======
yoko.awk が元になっており、複数のファイルの入力にも対応しています。
単語を単位として出現頻度と共起頻度を出力します。
rei.awk と組み合わせて使うためのスクリプトです。

### rei.awk
=======
eriko.awk / yoshino.awk の出力結果から、T値とMI値を求めます。
テキスト中の全ての共起について、中心語と共起語を組み合わせて計算します。
前方共起と後方共起は分けて計算されます。

### yoshino.awk
=======
eriko.awk と同じ機能を持ちますが、sachiko.awk と同様に　mecab や Unidic が不要です。
処理ファイルの作成には「茶まめ」を使用して下さい。
